{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "datadir = '../datasets/NNN/'\n",
    "fnames = utils.fnames(datadir)\n",
    "# data = pd.read_pickle('../datasets/NNN/all_unit_data.pkl')\n",
    "raster_data = pd.read_pickle('../datasets/NNN/unit_data_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, pair in enumerate(fnames):\n",
    "    if i>0:\n",
    "        break\n",
    "    gus_fname = os.path.join(datadir, pair[0])\n",
    "    proc_fname = os.path.join(datadir, pair[1])\n",
    "    \n",
    "    gus_data = utils.load_mat(gus_fname)\n",
    "    proc_data = scipy.io.loadmat(proc_fname)\n",
    "    \n",
    "    print('unit types:', len(proc_data['UnitType'][0]))\n",
    "    print('psth:', proc_data['mean_psth'].shape)\n",
    "    print('avg firing rate to all images:', proc_data['response_basic'].shape)\n",
    "    \n",
    "    mean_psth = proc_data['mean_psth']\n",
    "    unit_type = proc_data['UnitType'][0]\n",
    "    single_units = np.where(unit_type==1)\n",
    "    snr = proc_data['snr'].T\n",
    "    response = np.stack(gus_data['GoodUnitStrc']['response_matrix_img'])\n",
    "    \n",
    "    print(f'number of single units: {np.sum(unit_type==1)}')\n",
    "    \n",
    "    sns.heatmap(mean_psth[single_units], vmax=20)\n",
    "    plt.show()\n",
    "    \n",
    "    sns.boxplot(snr[single_units])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = data[data['unit_type']==1]\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,5))\n",
    "df = data\n",
    "\n",
    "sns.boxplot(df, x='monkey', y='snr_max', hue='unit_type', fliersize=1, ax=ax)\n",
    "plt.title('SNR max')\n",
    "plt.ylim(bottom = -1, top=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.groupby(['unit_type']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,8))\n",
    "\n",
    "df = data[(data['unit_type']==1) & (data['snr']>1)]\n",
    "dat = np.stack(df['avg_firing_rate'])\n",
    "\n",
    "sns.heatmap(dat, ax=ax, vmax=10)\n",
    "\n",
    "ax.set_ylabel('unit number')\n",
    "ax.set_xlabel('image idx')\n",
    "ax.set_xticks([], [])\n",
    "ax.set_yticks([], [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = data[(data['unit_type']==1) & (data['snr']>1)]\n",
    "\n",
    "fig,axes = plt.subplots(5,1,figsize=(10,20))\n",
    "\n",
    "for i in range(5):\n",
    "    num = round(random.random()*len(df))\n",
    "    dat = df.iloc[num]['img_psth']\n",
    "    sns.heatmap(dat, square=True, vmax=10, ax=axes[i])\n",
    "    axes[i].axis(\"off\")\n",
    "    axes[i].set_title(f'{df.iloc[i]['snr']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample\n",
    "# df = pd.DataFrame({'F_SI':..., 'B_SI':..., 'O_SI':...})\n",
    "\n",
    "# 1. \"Melt\" the dataframe to long form (for lineplotting with seaborn)\n",
    "df = data.copy()\n",
    "\n",
    "df_long = df.reset_index().melt(id_vars='index', value_vars=['F_SI', 'B_SI', 'O_SI'],\n",
    "                                var_name='SI_type', value_name='SI_value')\n",
    "df_long = df_long.rename(columns={\"index\": \"unit\"})  # index serves as unique unit id\n",
    "\n",
    "# 2. For grouping: For each unit, find which SI_type is maximal AND above cutoff\n",
    "cutoff = 0.5\n",
    "\n",
    "# Get for each unit the max SI value and its column\n",
    "def assign_group(row):\n",
    "    vals = row[['F_SI', 'B_SI', 'O_SI']]\n",
    "    maxval = vals.max()\n",
    "    if maxval < cutoff:\n",
    "        return 'None'\n",
    "    maxcol = vals.idxmax()\n",
    "    return maxcol  # will be 'F_SI', 'B_SI', or 'O_SI'\n",
    "\n",
    "df['group'] = data.apply(assign_group, axis=1)\n",
    "\n",
    "# 3. Add 'group' label to long version\n",
    "df_long['group'] = df_long['unit'].map(df['group'])\n",
    "\n",
    "# Filter out units not meeting any cutoff\n",
    "df_long_filtered = df_long[df_long['group'] != 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharey=True, sharex=True)\n",
    "\n",
    "groups = ['F_SI', 'B_SI', 'O_SI']\n",
    "for i, g in enumerate(groups):\n",
    "    fig,ax = plt.subplots(1,1,figsize=(8,5))\n",
    "    sub_df = df_long_filtered[df_long_filtered['group'] == g]\n",
    "    sns.lineplot(sub_df, x='SI_type', y='SI_value', sort=False,\n",
    "                 hue='unit', marker='o', palette = ['black'], alpha=0.05)\n",
    "    ax.set_title(f\"Group: {g}, {len(sub_df)}\")\n",
    "    ax.legend().remove()\n",
    "    ax.set_xlabel('category')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Selectivity Index')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unit = 'F_SI'\n",
    "face_df = raster_data[(raster_data[unit]>0.5) & (raster_data['unit_type'] == 1)]\n",
    "face_df = face_df[~(face_df['img_raster'].isna())] # some sessions do not have raster data?\n",
    "psth = face_df.iloc[13]['img_psth']\n",
    "sns.heatmap(psth[:, :1000].T, cmap=sns.color_palette(palette='Greys'))\n",
    "plt.show()\n",
    "\n",
    "x = np.stack(face_df['img_psth'].values)\n",
    "avg_face = np.mean(x, axis=0)\n",
    "sns.heatmap(avg_face[:, :1000].T, cmap=sns.color_palette(palette='Greys'))\n",
    "plt.title('Face responses to NSD images')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M = avg_face[:, :1000].T  # (1000, time)\n",
    "\n",
    "# 1. Compute row linkage (using, e.g., Euclidean or correlation distance)\n",
    "dists = pdist(M, metric='correlation')  # or 'euclidean', 'cosine', etc\n",
    "row_linkage = linkage(dists, method='average')  # method can be 'ward', 'average', etc\n",
    "\n",
    "# 2. Get the optimal leaf order from dendrogram\n",
    "dendro = dendrogram(row_linkage, no_plot=True)\n",
    "row_order = dendro['leaves']  # this is the order for the rows (images)\n",
    "\n",
    "sns.heatmap(M[row_order, :], cmap=sns.color_palette('Greys', as_cmap=True))\n",
    "plt.title('Face responses to NSD images (clustered)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Compute mean activity for each image\n",
    "row_means = M.mean(axis=1)  # shape: (num_images,)\n",
    "\n",
    "# 2. Get sort order (indices of rows), from highest to lowest mean\n",
    "row_order = np.argsort(row_means)[::-1]  # descending order\n",
    "\n",
    "# 3. Plot using the sorted order\n",
    "sns.heatmap(M[row_order, :], cmap=sns.color_palette('Greys', as_cmap=True))\n",
    "plt.title('NSD images (sorted by mean unit activity)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raster = np.stack(face_df['img_raster'].values)\n",
    "raster = np.mean(all_raster, axis=0)\n",
    "\n",
    "R = raster.T[:1000]\n",
    "row_means = R.mean(axis=1) \n",
    "row_order = np.argsort(row_means)[::-1]\n",
    "\n",
    "sns.heatmap(R[row_order, :], cmap=sns.color_palette('Greys', as_cmap=True))\n",
    "plt.title('NSD images (Raster plot)')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_raster = np.stack(face_df['img_raster'].values)\n",
    "raster = np.mean(all_raster, axis=0)\n",
    "\n",
    "R = raster.T[:1000]\n",
    "\n",
    "early_raster = all_raster[:, 100:170, :1000] # 70 - 150 msec\n",
    "late_raster = all_raster[:, 200:270, :1000] # 170-250 msec\n",
    "latelate_raster = all_raster[:, 300:370, :1000]\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 12))\n",
    "\n",
    "time_windows = [\n",
    "    ('spikes from 50-120 msec', early_raster),\n",
    "    ('spikes from 150-220 msec', late_raster),\n",
    "    ('spikes from 250-320 msec', latelate_raster)\n",
    "]\n",
    "\n",
    "for row, (title, raster) in enumerate(time_windows):\n",
    "    # Left: histogram\n",
    "    ax = axes[row, 0]\n",
    "    sspikes = np.sum(raster, axis=1)        # (units, images)\n",
    "    x = np.mean(sspikes, axis=0)            # mean population activity per image\n",
    "    sns.histplot(x, binwidth=0.01, ax=ax)\n",
    "    ax.set_ylim(top=150)\n",
    "    ax.set_xlim(right=1)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Mean spike count per image')\n",
    "    ax.set_ylabel('Count')\n",
    "\n",
    "    # Right: RDM\n",
    "    ax = axes[row, 1]\n",
    "    rdm = squareform(pdist(sspikes, metric='correlation'))  # shape (units, units)\n",
    "    sns.heatmap(rdm, ax=ax, cmap='mako', square=True)  # only cbar for top row for less clutter\n",
    "    ax.set_title('RDM (%s)' % title)\n",
    "    ax.set_xlabel('Unit')\n",
    "    ax.set_ylabel('Unit')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unit = 'F_SI'\n",
    "face_df = raster_data[(raster_data[unit]>0.5) & (raster_data['unit_type'] == 1) & (raster_data['snr_max'] > 20) & (raster_data['session'].isin([21,24,25,28,29,30,36,40]))]\n",
    "face_df = face_df[~(face_df['img_raster'].isna())] # some sessions do not have raster data?\n",
    "face_df['session'].unique(), len(face_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 254\n",
    "N = 50  # window for moving avg\n",
    "\n",
    "random.seed(5)\n",
    "\n",
    "example_units = random.sample(range(len(face_df)), 5)   # choose units you want to visualize\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(18, 6), sharex='col', sharey='row')\n",
    "\n",
    "for col, unit_idx in enumerate(example_units):\n",
    "    # Get normalized spike history for this unit and image\n",
    "    spike_history = face_df.iloc[unit_idx]['img_raster'][:, img_idx]\n",
    "    spike_history = spike_history / spike_history.max()\n",
    "\n",
    "    # --- Plot cumulative sum ---\n",
    "    ax = axes[0, col]\n",
    "    sns.lineplot(x=np.arange(len(spike_history)), y=np.cumsum(spike_history), ax=ax)\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.vlines(x=50, ymin=ymin, ymax=ymax, colors='red', linestyle='dashed')\n",
    "    ax.set_title(f'Unit {unit_idx} - cumulative')\n",
    "    ax.set_ylabel('spike count')\n",
    "\n",
    "    # --- Plot moving average ---\n",
    "    ax = axes[1, col]\n",
    "    moving_avg = np.convolve(spike_history, np.ones(N)/N, mode='valid')\n",
    "    sns.lineplot(x=np.arange(len(moving_avg)), y=moving_avg, ax=ax)\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.vlines(x=50, ymin=ymin, ymax=ymax, colors='red', linestyle='dashed')\n",
    "    ax.set_title(f'Unit {unit_idx} - moving avg')\n",
    "    ax.set_ylabel('firing rate')\n",
    "\n",
    "plt.suptitle(f'Example units for image {img_idx}', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../datasets/NNN/'\n",
    "fnames = utils.fnames(datadir)\n",
    "\n",
    "cols = ['session', 'monkey', 'F_SI', 'B_SI', 'O_SI']\n",
    "df = pd.DataFrame(columns=cols)\n",
    "\n",
    "total_units = 0\n",
    "for i, pair in tqdm(enumerate(fnames)):\n",
    "    gus_fname = os.path.join(datadir, pair[0])\n",
    "    proc_fname = os.path.join(datadir, pair[1])\n",
    "    m = re.match(r'Processed_ses(\\d+)_(\\d{6})_M(\\d+)_(\\d+)\\.mat', os.path.basename(proc_fname))\n",
    "    if i == 28:\n",
    "        print(f'skipping {proc_fname}...')\n",
    "        continue\n",
    "    if not m:\n",
    "        print(f\"Could not parse {proc_fname}\")\n",
    "        continue\n",
    "    try:\n",
    "        proc_data = scipy.io.loadmat(proc_fname)\n",
    "        \n",
    "        session_num = int(m.group(1))\n",
    "        monkey = int(m.group(3))\n",
    "        unit_types = proc_data['UnitType'][0]\n",
    "        num_units = len(proc_data['UnitType'][0])\n",
    "\n",
    "        bsi = proc_data['B_SI'].T.squeeze(); assert bsi.shape[0] == num_units\n",
    "        osi = proc_data['O_SI'].T.squeeze(); assert osi.shape[0] == num_units\n",
    "        fsi = proc_data['F_SI'].T.squeeze(); assert fsi.shape[0] == num_units\n",
    "        \n",
    "        for unit_idx in range(num_units):\n",
    "            df.loc[len(df)] = {\n",
    "                'session': session_num,\n",
    "                'monkey': monkey,\n",
    "                'F_SI': fsi[unit_idx],\n",
    "                'B_SI': bsi[unit_idx],\n",
    "                'O_SI': osi[unit_idx],\n",
    "            }\n",
    "        total_units += num_units\n",
    "\n",
    "    except AssertionError as e:\n",
    "        print(f\"Assertion failed for {proc_fname or gus_fname}: {e}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {proc_fname or gus_fname}: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['F_SI'] = df['F_SI']\n",
    "data['B_SI'] = df['B_SI']\n",
    "data['O_SI'] = df['O_SI']\n",
    "data.to_pickle('../datasets/NNN/all_unit_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dynamics]",
   "language": "python",
   "name": "conda-env-dynamics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
