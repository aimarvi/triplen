{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.manifold import MDS\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import manifold_dynamics.tuning_utils as tut\n",
    "\n",
    "RAND = 0\n",
    "RESP = (50,220)\n",
    "BASE = (-50,0)\n",
    "ONSET = 50\n",
    "RESP = slice(ONSET + RESP[0], ONSET + RESP[1])\n",
    "BASE = slice(ONSET + BASE[0], ONSET + BASE[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../datasets/NNN/'\n",
    "CAT = 'face'\n",
    "dat = pd.read_pickle(os.path.join(DATA_DIR, (f'{CAT}_roi_data.pkl')))\n",
    "print(f'Unique {CAT} ROIs: {list(dat['roi'].unique())}')\n",
    "\n",
    "# ROI_LIST = list(dat['roi'].unique())\n",
    "print(dat['roi'].value_counts())\n",
    "\n",
    "\n",
    "# load in prev data if this has been run before\n",
    "df = pd.read_pickle('../../datasets/NNN/face_rdms.pkl')\n",
    "ROI_LIST = ['MF1_8_F', 'Unknown_19_F', 'MF1_7_F', 'MF1_9_F']\n",
    "cache = {\n",
    "    row['ROI']: {k: row[k] for k in df.columns if k != 'ROI'}\n",
    "    for _, row in df.iterrows()\n",
    "}\n",
    "\n",
    "# DIRECTORY FOR FIGURES\n",
    "SAVE_DIR = './../../../buckets/manifold-dynamics/time-time/l2-norm'\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def geo_rdm(dat, roi, mode='top', step=5, k_max=200, metric='correlation'):\n",
    "    rng = np.random.default_rng(RAND)\n",
    "    sig = dat[dat['p_value'] < 0.05]\n",
    "    df = sig[sig['roi'] == roi]\n",
    "    if len(df) == 0:\n",
    "        raise ValueError(f\"No data for ROI {ROI}\")\n",
    "    X = np.stack(df['img_psth'].to_numpy())          # (units, time, images)\n",
    "\n",
    "    scores = np.nanmean(X[:, RESP, :], axis=(0,1)) - np.nanmean(X[:, BASE, :], axis=(0,1))\n",
    "    order = np.argsort(scores)[::-1] if mode == 'top' else rng.permutation(scores.size)\n",
    "\n",
    "    # ================= choose the image-set bins to calculate RDMs ========\n",
    "    sizes = [k for k in range(step, min(k_max, X.shape[2]) + 1, step)]\n",
    "    # =================== ramping step size ================================ \n",
    "    # sizes = [k for k in range(1, 2*step)] + [k for k in range(2*step, min(k_max, X.shape[2])+1, step)]\n",
    "    \n",
    "    rdvs = []\n",
    "    for k in tqdm(sizes):\n",
    "        idx = order[:k]\n",
    "        Ximg = X[:, :, idx] # (units, time, images)\n",
    "        Xrdv = np.array([pdist(Ximg[:, t, :].T, metric='correlation') for t in range(Ximg.shape[1])])\n",
    "        R = squareform(pdist(Xrdv, metric=metric))   # (time, time)\n",
    "        rdvs.append(R)\n",
    "    return sizes, rdvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cache = {}\n",
    "step = 1 # choose 1 so you can change it later on\n",
    "\n",
    "for _roi in ROI_LIST:\n",
    "    sizes_top,   top_rdms   = tut.geo_rdm(dat, roi=_roi, mode='top',   step=step)\n",
    "    # sizes_shuff, shuff_rdms = geo_rdm(dat, roi=_roi, mode='shuff', step=step)\n",
    "    \n",
    "    cache[_roi] = {\n",
    "        \"sizes_top\": sizes_top,\n",
    "        # \"sizes_shuff\": sizes_shuff,\n",
    "        \"top_rdms\": top_rdms,\n",
    "        # \"shuff_rdms\": shuff_rdms,\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame([{**{'ROI': roi},\n",
    "                    **vals} for roi,\n",
    "                   vals in cache.items()])\n",
    "# df.to_pickle('../../datasets/NNN/object_rdms.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MEAN SQUARED DIFFERENCE OVER SUCCESSIVE TIME POINTS\n",
    "\n",
    "step = 2\n",
    "cols = ['ROI', 'Scale', 'Derivative', 'Mode']\n",
    "diffs = pd.DataFrame(columns=cols)\n",
    "for _roi in ROI_LIST:\n",
    "    roi_dict = cache[_roi]\n",
    "    sizes = roi_dict['sizes_top']\n",
    "    top_rdms = roi_dict['top_rdms']\n",
    "    \n",
    "    R0 = top_rdms[step][triu]\n",
    "    for mode in ['top', 'shuff']:\n",
    "        rdms = roi_dict[f'{mode}_rdms']\n",
    "        triu = np.triu_indices_from(top_rdms[0], k=1)\n",
    "\n",
    "        ## single time point RDM, or average over previous time step chunk\n",
    "        # R0 = rdms[step][triu]\n",
    "        R0 = np.mean(np.array([rdm[triu] for rdm in rdms[0:t]]), axis=0)\n",
    "        \n",
    "        for t in np.arange(1*step, len(rdms), step):\n",
    "            prev = R0\n",
    "\n",
    "            ## same as above\n",
    "            # R0 = rdms[t-1][triu]\n",
    "            R0 = np.mean(np.array([rdm[triu] for rdm in rdms[t:t+step]]), axis=0)\n",
    "    \n",
    "            ## difference metric for times t, t'\n",
    "            diff = np.sqrt(np.sum((R0 - prev)**2)) # difference between t1, t2\n",
    "            # diff = np.sqrt(np.sum((R0)**2))\n",
    "            # diff = 1 - spearmanr(R0, prev).statistic # similairty between t1, t2\n",
    "    \n",
    "            diffs.loc[len(diffs)] = {'ROI': _roi, 'Scale': sizes[t-1], 'Derivative': diff, 'Mode': mode}\n",
    "            \n",
    "for r in ROI_LIST:\n",
    "    fig,ax = plt.subplots(1,1, figsize=(10,5))\n",
    "    sns.lineplot(diffs[diffs['ROI']==r], x='Scale', y='Derivative', hue='Mode', ax=ax)\n",
    "    ax.set_title(r)\n",
    "    plt.show()\n",
    "\n",
    "# for r in ROI_LIST:\n",
    "#     fig,ax = plt.subplots(1,1, figsize=(10,5))\n",
    "#     top_diff = diffs[(diffs['ROI']==r) & (diffs['Mode']=='top')]['Derivative']\n",
    "#     shuff_diff = diffs[(diffs['ROI']==r) & (diffs['Mode']=='shuff')]['Derivative']\n",
    "\n",
    "#     d = (top_diff.values-shuff_diff.values) / shuff_diff.values\n",
    "    \n",
    "#     sns.lineplot(x=np.arange(1*step, len(rdms), step), y=d, ax=ax)\n",
    "#     ax.set_title(r)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### LOOK AT AUTOCORRELATION OVER TIME?\n",
    "\n",
    "def rdm_autocorr(rdms):\n",
    "    triu = np.triu_indices_from(rdms[0], k=1)\n",
    "    T = len(rdms)\n",
    "    R = np.vstack([r[triu] for r in rdms])  # (T, features)\n",
    "\n",
    "    out = []\n",
    "    for t in tqdm(range(T)):\n",
    "        r_t = R[t]\n",
    "        future = R[t+1:]\n",
    "        if len(future)==0:\n",
    "            out.append(np.nan)\n",
    "            continue\n",
    "        corrs = np.array([spearmanr(r_t, f).statistic for f in future])\n",
    "        out.append(np.nanmean(corrs))\n",
    "    return np.array(out)\n",
    "\n",
    "for _roi in ['Unknown_19_F', 'MF1_7_F',]:\n",
    "    roi_dict = cache[_roi]\n",
    "    auto = rdm_autocorr(roi_dict['top_rdms'])\n",
    "    shuff = rdm_autocorr(roi_dict['shuff_rdms'])\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    sns.lineplot(auto, ax=ax)\n",
    "    sns.lineplot(shuff, ax=ax)\n",
    "    \n",
    "    ax.set_title(_roi)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### MAYBE ENTROPY OF RDM?\n",
    "\n",
    "def rdm_entropy(rdms):\n",
    "    triu = np.triu_indices_from(rdms[0], k=1)\n",
    "    H = []\n",
    "    for R in rdms[10:]:\n",
    "        v = np.abs(R[triu])\n",
    "        v = v / v.sum()\n",
    "        H.append(entropy(v))\n",
    "    return np.array(H)\n",
    "\n",
    "for _roi in ROI_LIST:\n",
    "    roi_dict = cache[_roi]\n",
    "    auto = rdm_entropy(roi_dict['top_rdms'])\n",
    "    shuff = rdm_entropy(roi_dict['shuff_rdms'])\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    sns.lineplot(auto, ax=ax)\n",
    "    sns.lineplot(shuff, ax=ax)\n",
    "    \n",
    "    ax.set_title(_roi)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### EFFECTIVE DIMENSIONALITY ?\n",
    "\n",
    "def effective_dim(R):\n",
    "    S = -0.5 * R**2\n",
    "    lam = np.linalg.eigvalsh(S)\n",
    "    lam = np.clip(lam,0,None)\n",
    "    return (lam.sum()**2) / (lam**2).sum()\n",
    "\n",
    "def ed_over_time(rdms):\n",
    "    return np.array([effective_dim(R) for R in rdms[2:]])\n",
    "\n",
    "for _roi in ROI_LIST:\n",
    "    roi_dict = cache[_roi]\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    sns.lineplot(ed_over_time(roi_dict['top_rdms']), ax=ax)\n",
    "    sns.lineplot(ed_over_time(roi_dict['shuff_rdms']), ax=ax)\n",
    "    ax.set_title(_roi)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for _roi in ['MF1_8_F', 'Unknown_19_F', 'MF1_7_F', 'MF1_9_F']:\n",
    "    step = 5\n",
    "\n",
    "    sizes_top,   top_rdms   = geo_rdm(dat, roi=_roi, mode='top',   step=step)\n",
    "    sizes_shuff, shuff_rdms = geo_rdm(dat, roi=_roi, mode='shuff', step=step)\n",
    "    \n",
    "    def rdm_diffs(rdm_seq, start=2):\n",
    "        R0 = rdm_seq[start]\n",
    "        triu = np.triu_indices_from(R0, k=1)\n",
    "        diffs = [\n",
    "            # 1 - spearmanr(rdm_seq[i][triu], rdm_seq[i-1][triu])[0]\n",
    "            np.sum(np.abs(rdm_seq[i][triu] - rdm_seq[i-1][triu]))\n",
    "            for i in range(start, len(rdm_seq))\n",
    "        ]\n",
    "        ks = [sizes_top[i] for i in range(start, len(rdm_seq))]\n",
    "        return ks, diffs\n",
    "    \n",
    "    k_top,   diffs_top   = rdm_diffs(top_rdms, start=1)\n",
    "    k_shuff, diffs_shuff = rdm_diffs(shuff_rdms, start=1)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"k\":     k_top + k_shuff,\n",
    "        \"diff\":  diffs_top + diffs_shuff,\n",
    "        \"mode\":  [\"top\"]*len(diffs_top) + [\"shuff\"]*len(diffs_shuff),\n",
    "    })\n",
    "    \n",
    "    df[\"diff_smooth\"] = df[\"diff\"].groupby(df[\"mode\"]).transform(\n",
    "        lambda v: gaussian_filter1d(v, sigma=2)\n",
    "    )\n",
    "    \n",
    "    sns.lineplot(data=df, x=\"k\", y=\"diff_smooth\", hue=\"mode\")\n",
    "    sns.lineplot(data=df, x=\"k\", y=\"diff\", hue=\"mode\", alpha=0.5)\n",
    "    \n",
    "    plt.xlabel(\"Number of images (k)\")\n",
    "    plt.ylabel(\"Absolute Difference\")\n",
    "    plt.title(f'{_roi}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ABS DISSIM FOR A SINGLE TIME POINT\n",
    "\n",
    "step = 5\n",
    "cols = ['ROI', 'Scale', 'Derivative', 'Mode']\n",
    "diffs = pd.DataFrame(columns=cols)\n",
    "for _roi in ROI_LIST:\n",
    "    roi_dict = cache[_roi]\n",
    "    sizes = roi_dict['sizes_top']\n",
    "   \n",
    "    for mode in ['top']: #, 'shuff']:\n",
    "        rdms = roi_dict[f'{mode}_rdms']\n",
    "        triu = np.triu_indices_from(rdms[0], k=1)\n",
    "\n",
    "        ## single time point RDM, or average over previous time step chunk\n",
    "        # R0 = rdms[step][triu]\n",
    "        R0 = np.mean(np.array([rdm[triu] for rdm in rdms[0:step]]), axis=0) #######################################\n",
    "        for t in np.arange(1*step, len(rdms), step):\n",
    "            prev = R0\n",
    "            ## same as above\n",
    "            # R0 = rdms[t-1][triu]\n",
    "            R0 = np.mean(np.array([rdm[triu] for rdm in rdms[t:t+step]]), axis=0) ######################################\n",
    "    \n",
    "            ## difference metric for times t, t'\n",
    "            # diff = np.sqrt(np.sum((R0)**2)) # L2/EUCLIDEAN NORM\n",
    "            diff = 1 - spearmanr(R0, prev).statistic\n",
    "    \n",
    "            diffs.loc[len(diffs)] = {'ROI': _roi, 'Scale': sizes[t-1], 'Derivative': diff, 'Mode': mode}\n",
    "\n",
    "\n",
    "customp = sns.color_palette('husl')\n",
    "diffs[\"diff_smooth\"] = diffs[\"Derivative\"].groupby(diffs[\"Mode\"]).transform(\n",
    "    lambda v: gaussian_filter1d(v, sigma=1)\n",
    ")\n",
    "mins = {}\n",
    "for r in ROI_LIST:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "    d = diffs[diffs['ROI'] == r]\n",
    "\n",
    "    # main lineplot\n",
    "    sns.lineplot(data=d, x='Scale', y='Derivative', hue='Mode', palette=customp, alpha=0.5, ax=ax)\n",
    "    sns.lineplot(data=d, x='Scale', y='diff_smooth', hue='Mode', palette=customp, ax=ax)\n",
    "\n",
    "    # add red dot + legend label for each Mode separately\n",
    "    labels  = list(ax.get_legend_handles_labels()[1])\n",
    "\n",
    "    for i, mode in enumerate(['top']): # enumerate(['top', 'shuff']):\n",
    "        dm = d[(d['Mode'] == mode)]\n",
    "        idx_min = dm['diff_smooth'].idxmin()\n",
    "        if np.isnan(idx_min):\n",
    "            continue\n",
    "        x_min   = dm.loc[idx_min, 'Scale']\n",
    "        y_min   = dm.loc[idx_min, 'diff_smooth']\n",
    "\n",
    "        # draw red dot\n",
    "        mins[r] = (x_min, y_min)\n",
    "        h = ax.scatter(x_min, y_min, color='red', marker='|', zorder=5)\n",
    "\n",
    "        # label for legend\n",
    "        labels[i] = f'{mode} min @ {int(x_min)}'\n",
    "\n",
    "    ax.legend(ax.get_legend_handles_labels()[0], labels, frameon=False).remove()\n",
    "    ax.set_title(r)\n",
    "    ax.set_ylabel('')\n",
    "    sns.despine(fig=fig, trim=True, offset=5)\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(SAVE_DIR, f'{r}-top-only.png')\n",
    "    # plt.savefig(out_path, dpi=300, transparent=True, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# import pickle \n",
    "\n",
    "# with open('../../datasets/NNN/object_mins.pkl', 'wb') as f:\n",
    "#     pickle.dump(mins, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# EFFECTIVE DIMENSIONALITY\n",
    "def effective_dimensionality(R):\n",
    "    S = -0.5 * R**2\n",
    "    lam = np.linalg.eigvalsh(S)\n",
    "    lam = np.clip(lam, 0, None)\n",
    "    return (lam.sum()**2) / (lam**2).sum()\n",
    "\n",
    "cache = {}\n",
    "\n",
    "for _roi in ['Unknown_19_F', 'MF1_7_F', 'MF1_9_F', 'MF1_8_F']:\n",
    "    step = 5\n",
    "\n",
    "    sizes_top,   top_rdms   = geo_rdm(dat, roi=_roi, mode='top',   step=step)\n",
    "    sizes_shuff, shuff_rdms = geo_rdm(dat, roi=_roi, mode='shuff', step=step)\n",
    "\n",
    "    def rdm_dim(rdm_seq, sizes):\n",
    "        dims = [effective_dimensionality(R) for R in rdm_seq]\n",
    "        return sizes, dims\n",
    "\n",
    "    k_top,   dims_top   = rdm_dim(top_rdms,   sizes_top)\n",
    "    k_shuff, dims_shuff = rdm_dim(shuff_rdms, sizes_shuff)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"k\":   k_top + k_shuff,\n",
    "        \"dim\": dims_top + dims_shuff,\n",
    "        \"mode\": [\"top\"]*len(dims_top) + [\"shuff\"]*len(dims_shuff),\n",
    "    })\n",
    "\n",
    "    df[\"dim_smooth\"] = df[\"dim\"].groupby(df[\"mode\"]).transform(\n",
    "        lambda v: gaussian_filter1d(v, sigma=2)\n",
    "    )\n",
    "\n",
    "    cache[_roi] = {\n",
    "        \"sizes_top\": sizes_top,\n",
    "        \"sizes_shuff\": sizes_shuff,\n",
    "        \"top_rdms\": top_rdms,\n",
    "        \"shuff_rdms\": shuff_rdms,\n",
    "    }\n",
    "\n",
    "    sns.lineplot(data=df, x=\"k\", y=\"dim_smooth\", hue=\"mode\")\n",
    "    sns.lineplot(data=df, x=\"k\", y=\"dim\", hue=\"mode\", alpha=0.4)\n",
    "\n",
    "    plt.xlabel(\"Number of images (k)\")\n",
    "    plt.ylabel(\"Effective dimensionality\")\n",
    "    plt.title(f\"{_roi}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv-py3 (manifold-dynamics)",
   "language": "python",
   "name": "manifold-dynamics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
