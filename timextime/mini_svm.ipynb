{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "import argparse\n",
    "from openselfsup.models import build_model\n",
    "from openselfsup.datasets import build_dataset\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import pdb\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from openselfsup.analysis.local_paths_from_func import get_model_kwargs_from_setting_func\n",
    "import openselfsup.analysis.response_extractor as response_extractor\n",
    "\n",
    "import dobs.tools as tools\n",
    "import dobs.folder as folder\n",
    "import dobs.folder_list as folder_list\n",
    "    \n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(z):\n",
    "    z = z / (torch.norm(z, p=2, dim=1, keepdim=True) + 1e-10)\n",
    "    return z\n",
    "    \n",
    "'''\n",
    "CHENGXU transform function (from tools.extract_face_img_states)\n",
    "'''\n",
    "def get_eval_transforms():\n",
    "    norm_cfg = dict(\n",
    "            mean=[0.485, 0.456, 0.406], \n",
    "            std=[0.229, 0.224, 0.225])\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(**norm_cfg),\n",
    "            ])\n",
    "    return transform\n",
    "\n",
    "transform = get_eval_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DOBS transform function (from Katherina)\n",
    "'''\n",
    "\n",
    "# image preprocessing steps     \n",
    "IMAGE_RESIZE=256\n",
    "IMAGE_SIZE=224\n",
    "GRAYSCALE_PROBABILITY=0.2\n",
    "resize_transform      = transforms.Resize(IMAGE_RESIZE)\n",
    "random_crop_transform = transforms.RandomCrop(IMAGE_SIZE)\n",
    "center_crop_transform = transforms.CenterCrop(IMAGE_SIZE)\n",
    "grayscale_transform   = transforms.RandomGrayscale(p=GRAYSCALE_PROBABILITY)\n",
    "normalize             = transforms.Normalize(mean=[0.5]*3,std=[0.5]*3)\n",
    "\n",
    "invert = transforms.RandomVerticalFlip(p=1.0)\n",
    "\n",
    "transform = transforms.Compose([resize_transform, \n",
    "                                            random_crop_transform, \n",
    "                                            grayscale_transform, \n",
    "                                            transforms.ToTensor(),\n",
    "                                            normalize,\n",
    "                                           ])\n",
    "\n",
    "invert_transform = transforms.Compose([resize_transform, \n",
    "                                            random_crop_transform, \n",
    "                                            grayscale_transform, \n",
    "                                            transforms.ToTensor(),\n",
    "                                            normalize,\n",
    "                                            invert\n",
    "                                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acts(model_file = 'configs/new_pplns/supervised/in_is224.py:r50_ep100_dobs_face_s0', foor='faces'):\n",
    "\n",
    "\n",
    "    _dat = 'faces' if 'face' in foor else 'objects'\n",
    "    _dat = 'cars' if 'car' in foor else _dat\n",
    "    \n",
    "    save_name = model_file.split(':')[1]\n",
    "    \n",
    "    md_kwgs = get_model_kwargs_from_setting_func(model_file)\n",
    "    model = build_model(md_kwgs['loaded_cfg'].model)\n",
    "    \n",
    "    layers = []\n",
    "    for name, module in model.named_modules():\n",
    "    \n",
    "        # #if len(name.split('.')) > 2 and name.split('.')[1] == '0':\n",
    "        # if 'relu' in name and 'neck' not in name and 'encoder_k' not in name and 'target_net' not in name:\n",
    "        if '4.2' in name and 'relu' in name:\n",
    "            if 'moco' in model_file or 'byol' in model_file:\n",
    "                name = '.'.join(['backbone'] + name.split('.')[2:])\n",
    "            layers.append(name)\n",
    "    \n",
    "    extractor = response_extractor.ResponseExtractor(\n",
    "                layers=layers,\n",
    "                **md_kwgs)\n",
    "    \n",
    "    test_data_dir=['/om2/group/nklab/shared/datasets/dobs_objface1000/%s_1000/test/'%_dat]\n",
    "    \n",
    "    ImageFolder = folder_list.ImageFolder\n",
    "    \n",
    "    dataset = ImageFolder(root=test_data_dir, \n",
    "                                  max_samples={'%s_1000'%_dat: 10},\n",
    "                                  maxout=True,\n",
    "                                  read_seed=None,\n",
    "                                  transform=transform,\n",
    "                                  includePaths=False)\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                                      batch_size=10,\n",
    "                                                      shuffle=False,\n",
    "                                                      num_workers=4,\n",
    "                                                      pin_memory=True)\n",
    "    \n",
    "    all_activations = []\n",
    "    \n",
    "    max_batches=100\n",
    "    for step, batch in enumerate(tqdm(data_loader, desc='act/grad')):\n",
    "        if max_batches is not None:\n",
    "            if step == max_batches:\n",
    "                break\n",
    "        x,y = batch\n",
    "        with torch.no_grad():  \n",
    "            act = extractor.get_activations(x)\n",
    "    \n",
    "            # model(x, mode='test')\n",
    "    \n",
    "            # act = act.cpu().numpy()\n",
    "            all_activations.append(act)\n",
    "    \n",
    "    # print(all_activations[0]['backbone.layer1.1.relu'].shape)\n",
    "    \n",
    "    ### Run activations through avg pool ###\n",
    "    m = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    act_dict = {layer: [] for layer in layers}\n",
    "    \n",
    "    print(len(all_activations))\n",
    "    \n",
    "    for batch in range(len(all_activations)):\n",
    "        for layer, act in all_activations[batch].items():\n",
    "            \n",
    "            z = m(torch.tensor(act))\n",
    "            z = l2_normalize(z)\n",
    "            if batch == 0:\n",
    "                act_dict[layer] = z\n",
    "            else:\n",
    "                act_dict[layer] = np.vstack((act_dict[layer], z))\n",
    "    \n",
    "    for layer, act in act_dict.items():\n",
    "        act_dict[layer] = act.reshape(act.shape[0], -1)\n",
    "    \n",
    "    # act_dict['backbone.layer1.1.relu'].shape\n",
    "    return act_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm(act_dict):\n",
    "    \n",
    "    perf_dict = {}\n",
    "    \n",
    "    print('=========== starting %s %s ==================='%(model_file,save_name))\n",
    "    for layer, act in act_dict.items():\n",
    "        # run SVM decoding\n",
    "        num_ids = 100\n",
    "        num_reps_id = 10\n",
    "        \n",
    "        num_samples = num_ids*num_reps_id\n",
    "        \n",
    "        \n",
    "        indTest = np.arange(0,num_samples,num_reps_id)\n",
    "        indAll = np.arange(0,num_samples)\n",
    "        \n",
    "        x = np.arange(0,num_ids)\n",
    "        trainCat = np.repeat(x,num_reps_id-1)\n",
    "        \n",
    "        perf_fold = np.zeros(shape=(num_reps_id,))\n",
    "        \n",
    "        for iFold in tqdm(range(num_reps_id)):\n",
    "        \n",
    "            indTrain = np.setdiff1d(indAll,indTest+iFold)\n",
    "        \n",
    "            dataTest = act[indTest+iFold,:]\n",
    "            dataTrain = act[indTrain,:]\n",
    "            \n",
    "            clf = svm.LinearSVC(dual='auto')\n",
    "            clf.fit(dataTrain,trainCat)\n",
    "        \n",
    "            dec = clf.predict(dataTest)\n",
    "            \n",
    "            diff = dec - x\n",
    "            perf = np.where(diff == 0)[0]\n",
    "            perf = len(perf)/num_ids\n",
    "        \n",
    "            perf_fold[iFold] = perf\n",
    "            \n",
    "        perf_dict[layer] = perf_fold\n",
    "        print(layer, np.mean(perf_fold))\n",
    "\n",
    "    return perf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "foor='car'\n",
    "\n",
    "model_list = ['configs/new_pplns/supervised/in_is224.py:r50_ep100_mini_%s_s0'%foor,\n",
    "'configs/new_pplns/simclr/r50.py:r50_ep100_mini_%s'%foor,\n",
    "]\n",
    "\n",
    "for model_file in model_list:\n",
    "    save_name = model_file.split(':')[1]\n",
    "    \n",
    "    act_dict = get_acts(model_file, foor)\n",
    "    break\n",
    "    perf_dict = run_svm(act_dict)\n",
    "\n",
    "    if 'moco' in model_file:\n",
    "        save_name = 'moco_%s'%save_name\n",
    "    elif 'simclr' in model_file:\n",
    "        save_name = 'simclr_%s'%save_name\n",
    "    elif 'byol' in model_file:\n",
    "        save_name = 'byol_%s'%save_name\n",
    "    elif 'dino' in model_file:\n",
    "        save_name = 'dino_%s'%save_name\n",
    "    elif 'supervised' in model_file:\n",
    "        save_name = 'supervised_%s'%save_name\n",
    "\n",
    "    with open('/om2/user/amarvi/FACE/saved_models/mini_svm_perf/%s.pkl'%save_name, 'wb') as f:\n",
    "        pickle.dump(perf_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_dict['backbone.layer4.2.relu'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/om2/user/amarvi/FACE/saved_models/mini_svm_perf/'\n",
    "cols = ['model', 'dataset', 'size', 'perf', 'layer']\n",
    "df = pd.DataFrame(columns = cols)\n",
    "\n",
    "for sub_dir in os.listdir(root):\n",
    "    model = sub_dir.split('_')[0]\n",
    "    if model not in ['moco', 'byol', 'simclr', 'supervised']:\n",
    "        continue\n",
    "    dataset = sub_dir.split('_')[4].split('.')[0]\n",
    "    dir = os.path.join(root, sub_dir)\n",
    "    with open(dir, 'rb') as f:\n",
    "        dat = pickle.load(f)\n",
    "        print(sub_dir, list(dat)[-1])\n",
    "        # acts[sub_dir] = dat[list(dat)[-1]]\n",
    "        df = pd.concat([df, pd.DataFrame([[model, dataset, '100', np.array(dat[list(dat)[-1]]), list(dat)[-1]]], columns=df.columns)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# df.to_pickle('/om2/user/amarvi/FACE/saved_models/svm_mini_all.pkl')\n",
    "df = pd.read_pickle('/om2/user/amarvi/FACE/saved_models/svm_mini_exploded.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['supervised', 'simclr']\n",
    "custom_dict = {model_name: index for index, model_name in enumerate(models)}\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = df.loc[(df['model'].isin(models)) & (df['size'].isin(['100']))]\n",
    "print(\"Filtered DataFrame:\\n\", filtered_df)\n",
    "\n",
    "# Explode the `perf` column\n",
    "exploded_df = filtered_df.explode('perf')\n",
    "exploded_df['perf'] = exploded_df['perf'].astype(float)\n",
    "print(\"Exploded DataFrame:\\n\", exploded_df)\n",
    "\n",
    "# # Group and Aggregate\n",
    "grouped_df = exploded_df.groupby(['model', 'dataset'])['perf'].agg(['mean', 'std']).reset_index()\n",
    "print(\"Grouped and Aggregated DataFrame:\\n\", grouped_df)\n",
    "\n",
    "# Sort with Custom Key\n",
    "sorted_df = grouped_df.sort_values(by=['model'], key=lambda x: x.map(custom_dict))\n",
    "print(\"Sorted DataFrame:\\n\", sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = (1,0,0)\n",
    "c2 = (1,0.65,0)\n",
    "c3 = (0.42,0.00,0.50)\n",
    "custom_dict = {'supervised': 0, 'simclr': 1} \n",
    "\n",
    "adict = {2: 1, 4: 0.7, 6: 0.5}\n",
    "models = ['supervised', 'simclr']\n",
    "order = ['obj', 'face', 'car']\n",
    "\n",
    "grouped_df = df.loc[(df['model'].isin(models)) & (df['size'].isin(['100']))].groupby(['model', 'dataset'])['perf'].agg(['mean', 'std']).reset_index().sort_values(by=['model'], key=lambda x: x.map(custom_dict))\n",
    "sns.barplot(data=grouped_df, x='dataset', y='mean', hue='model', order=order, edgecolor='gray')\n",
    "\n",
    "sv = len(order)\n",
    "for i in range(2*sv):\n",
    "    match i:\n",
    "        case 0:\n",
    "            plt.gca().patches[i].set_fc(c2)\n",
    "            plt.gca().patches[i].set_hatch('//')\n",
    "        case 1:\n",
    "            plt.gca().patches[i].set_fc(c1)\n",
    "            plt.gca().patches[i].set_hatch('//')\n",
    "        case 2:\n",
    "            plt.gca().patches[i].set_fc(c3)\n",
    "            plt.gca().patches[i].set_hatch('//')\n",
    "        case 3:\n",
    "            plt.gca().patches[i].set_fc((c2, 0.7))\n",
    "        case 4:\n",
    "            plt.gca().patches[i].set_fc((c1, 0.7))\n",
    "        case 5:\n",
    "            plt.gca().patches[i].set_fc((c3, 0.7))\n",
    "\n",
    "\n",
    "plt.legend().remove()\n",
    "# plt.xticks(range(sv), ['objects', 'faces', 'cars'])\n",
    "plt.xticks([], [])\n",
    "plt.xlabel('')\n",
    "plt.ylim([0, 1])\n",
    "plt.yticks(np.arange(0,1,0.2), [])\n",
    "plt.ylabel('')\n",
    "sns.despine(offset=5, bottom=True, trim=True)\n",
    "\n",
    "for i in range(len(grouped_df)):\n",
    "    x = plt.gca().patches[i].get_x()\n",
    "    w = plt.gca().patches[i].get_width()\n",
    "    h = plt.gca().patches[i].get_height()\n",
    "    err = grouped_df.iloc[i]['std']\n",
    "    plt.vlines(x+w/2, h-err, h+err, color='gray')\n",
    "\n",
    "plt.title('')\n",
    "plt\n",
    "# plt.savefig('/om2/user/amarvi/FACE/figs/svm_cars.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('/om2/user/amarvi/FACE/figs/svm_cars_fixed.png', dpi = 1000, bbox_inches = 'tight', format='png', transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
