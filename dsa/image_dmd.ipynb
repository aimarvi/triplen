{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import dot, multiply, diag, power\n",
    "from numpy import pi, exp, sin, cos\n",
    "from numpy.linalg import inv, eig, pinv, solve\n",
    "from scipy.linalg import svd, svdvals\n",
    "from math import floor, ceil # python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def dmd(X, Y, truncate=None):\n",
    "    '''\n",
    "    version created by Robert Taylor\n",
    "    for more info: https://humaticlabs.com/blog/dmd-python/\n",
    "\n",
    "    in this funciton, truncate == r\n",
    "    '''\n",
    "    if truncate == 0:\n",
    "        # return empty vectors\n",
    "        mu = np.array([], dtype='complex')\n",
    "        Phi = np.zeros([X.shape[0], 0], dtype='complex')\n",
    "    else:\n",
    "        U2,Sig2,Vh2 = svd(X, False) # SVD of input matrix\n",
    "        r = len(Sig2) if truncate is None else truncate # rank truncation\n",
    "        U = U2[:,:r]\n",
    "        Sig = diag(Sig2)[:r,:r]\n",
    "        V = Vh2.conj().T[:,:r]\n",
    "        Atil = dot(dot(dot(U.conj().T, Y), V), inv(Sig)) # build A tilde\n",
    "        mu,W = eig(Atil)\n",
    "        Phi = dot(dot(dot(Y, V), inv(Sig)), W) # build DMD modes\n",
    "    return mu, Phi\n",
    "\n",
    "def svht(X, sv=None):\n",
    "    # svht for sigma unknown\n",
    "    m,n = sorted(X.shape) # ensures m <= n\n",
    "    beta = m / n # ratio between 0 and 1\n",
    "    if sv is None:\n",
    "        sv = svdvals(X)\n",
    "    sv = np.squeeze(sv)\n",
    "    omega_approx = 0.56 * beta**3 - 0.95 * beta**2 + 1.82 * beta + 1.43\n",
    "    return np.median(sv) * omega_approx\n",
    "\n",
    "def mrdmd(D, level=0, bin_num=0, offset=0, max_levels=20, max_cycles=2, do_svht=True):\n",
    "    \"\"\"\n",
    "    Compute the multi-resolution DMD on the dataset `D`, returning a list of nodes\n",
    "    in the hierarchy. Each node represents a particular \"time bin\" (window in time) at\n",
    "    a particular \"level\" of the recursion (time scale). The node is an object consisting\n",
    "    of the various data structures generated by the DMD at its corresponding level and\n",
    "    time bin. The `level`, `bin_num`, and `offset` parameters are for record keeping \n",
    "    during the recursion and should not be modified unless you know what you are doing.\n",
    "    The `max_levels` parameter controls the maximum number of levels. The `max_cycles`\n",
    "    parameter controls the maximum number of mode oscillations in any given time scale \n",
    "    that qualify as \"slow\". The `do_svht` parameter indicates whether or not to perform\n",
    "    optimal singular value hard thresholding.\n",
    "\n",
    "    More info here: https://humaticlabs.com/blog/mrdmd-python/\n",
    "    \"\"\"\n",
    "\n",
    "    # 4 times nyquist limit to capture cycles\n",
    "    nyq = 8 * max_cycles\n",
    "\n",
    "    # time bin size\n",
    "    bin_size = D.shape[1]\n",
    "    if bin_size < nyq:\n",
    "        return []\n",
    "\n",
    "    # extract subsamples \n",
    "    step = floor(bin_size / nyq) # max step size to capture cycles\n",
    "    _D = D[:,::step]\n",
    "    X = _D[:,:-1]\n",
    "    Y = _D[:,1:]\n",
    "\n",
    "    # determine rank-reduction\n",
    "    if do_svht:\n",
    "        _sv = svdvals(_D)\n",
    "        tau = svht(_D, sv=_sv)\n",
    "        r = sum(_sv > tau)\n",
    "    else:\n",
    "        r = min(X.shape)\n",
    "\n",
    "    # compute dmd\n",
    "    mu,Phi = dmd(X, Y, r)\n",
    "\n",
    "    # frequency cutoff (oscillations per timestep)\n",
    "    rho = max_cycles / bin_size\n",
    "\n",
    "    # consolidate slow eigenvalues (as boolean mask)\n",
    "    slow = (np.abs(np.log(mu) / (2 * pi * step))) <= rho\n",
    "    n = sum(slow) # number of slow modes\n",
    "\n",
    "    # extract slow modes (perhaps empty)\n",
    "    mu = mu[slow]\n",
    "    Phi = Phi[:,slow]\n",
    "\n",
    "    if n > 0:\n",
    "\n",
    "        # vars for the objective function for D (before subsampling)\n",
    "        Vand = np.vander(power(mu, 1/step), bin_size, True)\n",
    "        P = multiply(dot(Phi.conj().T, Phi), np.conj(dot(Vand, Vand.conj().T)))\n",
    "        q = np.conj(diag(dot(dot(Vand, D.conj().T), Phi)))\n",
    "\n",
    "        # find optimal b solution\n",
    "        b_opt = solve(P, q).squeeze()\n",
    "\n",
    "        # time evolution\n",
    "        Psi = (Vand.T * b_opt).T\n",
    "\n",
    "    else:\n",
    "\n",
    "        # zero time evolution\n",
    "        b_opt = np.array([], dtype='complex')\n",
    "        Psi = np.zeros([0, bin_size], dtype='complex')\n",
    "\n",
    "    # dmd reconstruction\n",
    "    D_dmd = dot(Phi, Psi)   \n",
    "\n",
    "    # remove influence of slow modes\n",
    "    D = D - D_dmd\n",
    "\n",
    "    # record keeping\n",
    "    node = type('Node', (object,), {})()\n",
    "    node.level = level            # level of recursion\n",
    "    node.bin_num = bin_num        # time bin number\n",
    "    node.bin_size = bin_size      # time bin size\n",
    "    node.start = offset           # starting index\n",
    "    node.stop = offset + bin_size # stopping index\n",
    "    node.step = step              # step size\n",
    "    node.rho = rho                # frequency cutoff\n",
    "    node.r = r                    # rank-reduction\n",
    "    node.n = n                    # number of extracted modes\n",
    "    node.mu = mu                  # extracted eigenvalues\n",
    "    node.Phi = Phi                # extracted DMD modes\n",
    "    node.Psi = Psi                # extracted time evolution\n",
    "    node.b_opt = b_opt            # extracted optimal b vector\n",
    "    nodes = [node]\n",
    "\n",
    "    # split data into two and do recursion\n",
    "    if level < max_levels:\n",
    "        split = ceil(bin_size / 2) # where to split\n",
    "        nodes += mrdmd(\n",
    "            D[:,:split],\n",
    "            level=level+1,\n",
    "            bin_num=2*bin_num,\n",
    "            offset=offset,\n",
    "            max_levels=max_levels,\n",
    "            max_cycles=max_cycles,\n",
    "            do_svht=do_svht\n",
    "            )\n",
    "        nodes += mrdmd(\n",
    "            D[:,split:],\n",
    "            level=level+1,\n",
    "            bin_num=2*bin_num+1,\n",
    "            offset=offset+split,\n",
    "            max_levels=max_levels,\n",
    "            max_cycles=max_cycles,\n",
    "            do_svht=do_svht\n",
    "            )\n",
    "\n",
    "    return nodes\n",
    "\n",
    "def stitch(nodes, level):\n",
    "    \n",
    "    # get length of time dimension\n",
    "    start = min([nd.start for nd in nodes])\n",
    "    stop = max([nd.stop for nd in nodes])\n",
    "    t = stop - start\n",
    "\n",
    "    # extract relevant nodes\n",
    "    nodes = [n for n in nodes if n.level == level]\n",
    "    nodes = sorted(nodes, key=lambda n: n.bin_num)\n",
    "    \n",
    "    # stack DMD modes\n",
    "    Phi = np.hstack([n.Phi for n in nodes])\n",
    "    \n",
    "    # allocate zero matrix for time evolution\n",
    "    nmodes = sum([n.n for n in nodes])\n",
    "    Psi = np.zeros([nmodes, t], dtype='complex')\n",
    "    \n",
    "    # copy over time evolution for each time bin\n",
    "    i = 0\n",
    "    for n in nodes:\n",
    "        _nmodes = n.Psi.shape[0]\n",
    "        Psi[i:i+_nmodes,n.start:n.stop] = n.Psi\n",
    "        i += _nmodes\n",
    "    \n",
    "    return Phi,Psi\n",
    "\n",
    "def mr_recon(D):\n",
    "    nodes = mrdmd(D)\n",
    "    \n",
    "    Phi0,Psi0 = stitch(nodes, 0)\n",
    "    Phi1,Psi1 = stitch(nodes, 1)\n",
    "    Phi2,Psi2 = stitch(nodes, 2)\n",
    "    \n",
    "    levels = sorted({nd.level for nd in nodes})\n",
    "    D_hat_full = sum(stitch(nodes, l)[0] @ stitch(nodes, l)[1] for l in levels)\n",
    "    \n",
    "    D_iter = None\n",
    "    for l in levels:\n",
    "        fig, axes = plt.subplots(1,2, figsize=(15,5))\n",
    "        ax = axes[1]\n",
    "        _d = stitch(nodes, l)[0] @ stitch(nodes, l)[1]\n",
    "        sns.heatmap(_d.real, cbar=False, square=True, ax=ax)\n",
    "        ax.set_axis_off()\n",
    "        \n",
    "        if D_iter is None:\n",
    "            D_iter = _d.real\n",
    "        else:\n",
    "            D_iter = D_iter + _d.real\n",
    "            \n",
    "        ax = axes[0]\n",
    "        sns.heatmap(D_iter, cbar=False, square=True, ax=ax)\n",
    "        ax.set_axis_off()\n",
    "        plt.show()\n",
    "        \n",
    "    return nodes\n",
    "\n",
    "def plot_eigs(nodes, levels, combined=False):\n",
    "    p = np.linspace(0, 2*np.pi, 100)\n",
    "    \n",
    "    if combined:\n",
    "        # all on one plot\n",
    "        fix,ax = plt.subplots(1,1)\n",
    "        ax.plot(np.cos(p), np.sin(p), c=\"k\")\n",
    "        \n",
    "        for l in levels:\n",
    "            ns = [n for n in nodes if n.level == l]\n",
    "            eigs = []\n",
    "            for n in ns:\n",
    "                eigs.extend(n.mu)\n",
    "            eigs = np.array(eigs)\n",
    "            ax.scatter(eigs.real, eigs.imag, alpha=0.25, label=l)\n",
    "        \n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_title('wrt unit circle')\n",
    "        ax.legend()\n",
    "        ax.set_xlim(left = 0)\n",
    "        \n",
    "        ax.set_xlabel('Re'); ax.set_ylabel('Im')\n",
    "    else:\n",
    "        fix,axes = plt.subplots(1,len(levels), sharey=True)\n",
    "        # plot unit circle\n",
    "        for idx,l in enumerate(levels):\n",
    "            ax = axes[idx]\n",
    "            ax.plot(np.cos(p), np.sin(p), c=\"k\")\n",
    "            \n",
    "            ns = [n for n in nodes if n.level == l]\n",
    "            eigs = []\n",
    "            for n in ns:\n",
    "                eigs.extend(n.mu)\n",
    "            eigs = np.array(eigs)\n",
    "            ax.scatter(eigs.real, eigs.imag, alpha=.5, c='red', label=l)\n",
    "        \n",
    "            ax.set_aspect(\"equal\")\n",
    "            ax.set_xlim(left = 0, right=1.2)\n",
    "            ax.set_title(f'level {l}')\n",
    "            ax.set_axis_off()\n",
    "    plt.show()\n",
    "    \n",
    "def level_energy(nodes):\n",
    "    levs = sorted({n.level for n in nodes})\n",
    "    E = []\n",
    "    for ℓ in levs:\n",
    "        Phi, Psi = stitch(nodes, ℓ)\n",
    "        E.append(np.linalg.norm(Phi @ Psi, 'fro')**2)\n",
    "    E = np.array(E); return E / E.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../datasets/NNN/'\n",
    "dat = pd.read_pickle(os.path.join(DATA_DIR, ('object_roi_data.pkl')))\n",
    "print(f'Unique face ROIs: {list(dat['roi'].unique())}')\n",
    "\n",
    "img_sets = {\n",
    "    \"all_faces\":  np.arange(1000, 1024),\n",
    "    \"all_bodies\": np.concatenate([\n",
    "        np.arange(1025, 1031),\n",
    "        np.arange(1042, 1048),\n",
    "        np.arange(1049, 1061)\n",
    "    ]),\n",
    "    \"all_objects\": np.concatenate([\n",
    "        np.arange(1024,1025),\n",
    "        np.arange(1031, 1042),\n",
    "        np.arange(1048,1049),\n",
    "        np.arange(1061, 1072)\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = 'Unknown_22_O' # Unknown_19_F, MF1_8_F, MF1_9_F, MB1_3_B, MB2_20_B, Unknown_27_B, Unknown_22_O, MO2_21_O\n",
    "PVAL = 0.05\n",
    "\n",
    "# load in per-image psth\n",
    "sig = dat[dat['p_value'] < PVAL]\n",
    "df = sig[sig['roi'] == ROI]\n",
    "X = np.stack(df['img_psth'].to_numpy())\n",
    "print(f'Loaded unit-level data for each image. Shape:', X.shape, '---> (units, time points, images)')\n",
    "\n",
    "# center the data per unit and per image\n",
    "X_centered = X - X.mean(axis=1, keepdims=True)\n",
    "print('Centered shape:', X_centered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Edf = pd.DataFrame(columns=['level', 'energy', 'category'])\n",
    "\n",
    "for k, v in img_sets.items():\n",
    "    # dmd nodes for each image\n",
    "    nodes = [mrdmd(X_centered[:, :, i]) for i in v]\n",
    "    \n",
    "    E_cat = np.vstack([level_energy(n) for n in nodes])\n",
    "\n",
    "    # store all values, one row per image × level\n",
    "    for img_idx in range(E_cat.shape[0]):\n",
    "        for level_idx in range(E_cat.shape[1]):\n",
    "            Edf.loc[len(Edf)] = {\n",
    "                'level': level_idx,\n",
    "                'energy': E_cat[img_idx, level_idx],\n",
    "                'category': k.split('_')[-1]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "sns.barplot(data=Edf, x='level', y='energy', hue='category', estimator = 'median', errorbar='se', ax=ax)\n",
    "ax.set_title('Per-level Energy')\n",
    "sns.despine(fig=fig, trim=True, offset=5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(dynamics)",
   "language": "python",
   "name": "dynamics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
