{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../datasets/NNN/'\n",
    "dat = pd.read_pickle(os.path.join(DATA_DIR, ('face_roi_data.pkl')))\n",
    "print(f'Unique face ROIs: {list(dat['roi'].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = 'MF1_8_F'\n",
    "PVAL = 0.05\n",
    "METRIC = 'correlation'\n",
    "\n",
    "roi_dat = dat[(dat['roi']==ROI) & (dat['p_value']<PVAL)].reset_index(drop=True)\n",
    "# units, time points, images\n",
    "X = np.stack(roi_dat['img_psth']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sets = {'all images': np.arange(1000,1072), \n",
    "           'all faces': np.arange(1000,1024),\n",
    "           'monkey faces':  np.concatenate([np.arange(1000,1006), np.arange(1009,1016)]),\n",
    "           'human faces': np.concatenate([np.arange(1006,1009), np.arange(1016,1025)]),\n",
    "           'all nonfaces': np.arange(1025,1072),\n",
    "            'all objects': np.setdiff1d(np.arange(1000, 1072), np.concatenate([np.arange(1000,1024), np.arange(1025,1031), np.arange(1043,1049), np.arange(1051,1062)])),\n",
    "           'monkey bodies': np.concatenate([np.arange(1026,1031), np.arange(1043,1049)]),\n",
    "            'animal bodies': np.concatenate([np.arange(1026,1031), np.arange(1043,1049), np.arange(1051,1062)]),\n",
    "           }\n",
    "# pairwise distances between consecutive timepoints\n",
    "DISTANCE = \"chebyshev\"\n",
    "\n",
    "timepoints = np.arange(0, 450)\n",
    "for label, idxs, in img_sets.items():\n",
    "    img_resp = X[:, timepoints, :]\n",
    "    img_resp = img_resp[:, :, idxs]\n",
    "    vRDMs = []\n",
    "    for t in range(img_resp.shape[1]):\n",
    "        t_resp = img_resp[:, t, :]\n",
    "        vRDM = pdist(t_resp, metric=METRIC)\n",
    "        vRDMs.append(vRDM)\n",
    "    vRDMs = np.array(vRDMs)\n",
    "    vclean = np.nan_to_num(vRDMs)\n",
    "    \n",
    "    # true velocity\n",
    "    vel_true = np.array([\n",
    "        cdist(vclean[t:t+1], vclean[t+1:t+2], metric=DISTANCE)[0, 0]\n",
    "        for t in range(vclean.shape[0]-1)\n",
    "    ])\n",
    "    \n",
    "    # shuffled (permute time indices)\n",
    "    shuff_idx = np.random.permutation(vclean.shape[0])\n",
    "    vshuff = vclean[shuff_idx]\n",
    "    vel_shuff = np.array([\n",
    "        cdist(vshuff[t:t+1], vshuff[t+1:t+2], metric=DISTANCE)[0, 0]\n",
    "        for t in range(vshuff.shape[0]-1)\n",
    "    ])\n",
    "\n",
    "    win = 2  # smoothing window size\n",
    "    kernel = np.ones(win) / win\n",
    "    vel_smooth = np.convolve(vel_true, kernel, mode='same')\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    \n",
    "    ax.plot(vel_true, color='lightgray', label='Raw', alpha=0.5)\n",
    "    ax.plot(vel_smooth, color='black', linewidth=2, label=f'{win}-pt running avg')\n",
    "    ax.axhline(y=np.mean(vel_shuff), color='red')\n",
    "    ax.set_title(f'{label}')\n",
    "    \n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Velocity\")\n",
    "    plt.legend(frameon=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sets = {'all images': np.arange(1000,1072), \n",
    "           'all faces': np.arange(1000,1024),\n",
    "           'monkey faces':  np.concatenate([np.arange(1000,1006), np.arange(1009,1016)]),\n",
    "           'human faces': np.concatenate([np.arange(1006,1009), np.arange(1016,1025)]),\n",
    "           'all nonfaces': np.arange(1025,1072),\n",
    "            'all objects': np.setdiff1d(np.arange(1000, 1072), np.concatenate([np.arange(1000,1024), np.arange(1025,1031), np.arange(1043,1049), np.arange(1051,1062)])),\n",
    "           'monkey bodies': np.concatenate([np.arange(1026,1031), np.arange(1043,1049)]),\n",
    "            'animal bodies': np.concatenate([np.arange(1026,1031), np.arange(1043,1049), np.arange(1051,1062)]),\n",
    "           }\n",
    "# pairwise distances between consecutive timepoints\n",
    "DISTANCE = \"euclidean\"\n",
    "\n",
    "def velocity(X, metric=\"euclidean\"):\n",
    "    return np.array([cdist(X[t:t+1], X[t+1:t+2], metric=metric)[0,0]\n",
    "                     for t in range(X.shape[0]-1)])\n",
    "\n",
    "for label, idxs, in img_sets.items():\n",
    "    img_resp = X[:, :, idxs]\n",
    "    vRDMs = []\n",
    "    for t in range(img_resp.shape[1]):\n",
    "        t_resp = img_resp[:, t, :]\n",
    "        vRDM = pdist(t_resp, metric=METRIC)\n",
    "        vRDMs.append(vRDM)\n",
    "    vRDMs = np.array(vRDMs)\n",
    "    vclean = np.nan_to_num(vRDMs)\n",
    "    \n",
    "   # true velocity\n",
    "    vel_true = velocity(vclean)\n",
    "    \n",
    "    # permutation (chance) â€” shuffle time, repeat, and average\n",
    "    rng = np.random.default_rng(0)\n",
    "    n_shuffle = 100\n",
    "    vel_shuffs = np.empty((n_shuffle, vel_true.size))\n",
    "    for s in tqdm(range(n_shuffle)):\n",
    "        vshuff = vclean[rng.permutation(vclean.shape[0])]\n",
    "        vel_shuffs[s] = velocity(vshuff)\n",
    "    \n",
    "    # per-time null mean/CI and global test on mean velocity\n",
    "    null_mean = vel_shuffs.mean(axis=0)\n",
    "    null_lo   = np.percentile(vel_shuffs, 2.5, axis=0)\n",
    "    null_hi   = np.percentile(vel_shuffs, 97.5, axis=0)\n",
    "    \n",
    "    true_mean = vel_true.mean()\n",
    "    null_mean_dist = vel_shuffs.mean(axis=1)\n",
    "    null_med = np.median(null_mean_dist)\n",
    "    pval = (np.sum(null_mean_dist >= true_mean) + 1) / (n_shuffle + 1)\n",
    "    \n",
    "    diff = true_mean - null_med\n",
    "    print(f\"Mean true velocity: {true_mean:.4f}\\nMean shuff velocity: {null_med:.4f}\\n\\nDifference:{diff:.4f}\")\n",
    "    print(f\"Permutation p-value (greater-than): {pval:.4g}\")\n",
    "\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    sns.histplot(vel_true, ax=ax, label=f'orig ({true_mean})')\n",
    "    ax.axvline(x=np.mean(vel_true), color='red')\n",
    "    for i in range(10):\n",
    "        sns.histplot(vel_shuffs[i], alpha=0.01, ax=ax)\n",
    "    ax.axvline(x=null_med, color='black')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Distance (t, t+1)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    ax.set_title(f'rep. geom. velocity: {label}')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(dynamics)",
   "language": "python",
   "name": "dynamics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
