{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import dot, multiply, diag, power\n",
    "from numpy import pi, exp, sin, cos\n",
    "from numpy.linalg import inv, eig, pinv, solve\n",
    "from scipy.linalg import svd, svdvals\n",
    "from math import floor, ceil # python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmd(X, Y, truncate=None):\n",
    "    '''\n",
    "    version created by Robert Taylor\n",
    "    for more info: https://humaticlabs.com/blog/dmd-python/\n",
    "\n",
    "    in this funciton, truncate == r\n",
    "    '''\n",
    "    if truncate == 0:\n",
    "        # return empty vectors\n",
    "        mu = np.array([], dtype='complex')\n",
    "        Phi = np.zeros([X.shape[0], 0], dtype='complex')\n",
    "    else:\n",
    "        U2,Sig2,Vh2 = svd(X, False) # SVD of input matrix\n",
    "        r = len(Sig2) if truncate is None else truncate # rank truncation\n",
    "        U = U2[:,:r]\n",
    "        Sig = diag(Sig2)[:r,:r]\n",
    "        V = Vh2.conj().T[:,:r]\n",
    "        Atil = dot(dot(dot(U.conj().T, Y), V), inv(Sig)) # build A tilde\n",
    "        mu,W = eig(Atil)\n",
    "        Phi = dot(dot(dot(Y, V), inv(Sig)), W) # build DMD modes\n",
    "    return mu, Phi\n",
    "\n",
    "def svht(X, sv=None):\n",
    "    # svht for sigma unknown\n",
    "    m,n = sorted(X.shape) # ensures m <= n\n",
    "    beta = m / n # ratio between 0 and 1\n",
    "    if sv is None:\n",
    "        sv = svdvals(X)\n",
    "    sv = np.squeeze(sv)\n",
    "    omega_approx = 0.56 * beta**3 - 0.95 * beta**2 + 1.82 * beta + 1.43\n",
    "    return np.median(sv) * omega_approx\n",
    "\n",
    "def mrdmd(D, level=0, bin_num=0, offset=0, max_levels=20, max_cycles=2, do_svht=True):\n",
    "    \"\"\"\n",
    "    Compute the multi-resolution DMD on the dataset `D`, returning a list of nodes\n",
    "    in the hierarchy. Each node represents a particular \"time bin\" (window in time) at\n",
    "    a particular \"level\" of the recursion (time scale). The node is an object consisting\n",
    "    of the various data structures generated by the DMD at its corresponding level and\n",
    "    time bin. The `level`, `bin_num`, and `offset` parameters are for record keeping \n",
    "    during the recursion and should not be modified unless you know what you are doing.\n",
    "    The `max_levels` parameter controls the maximum number of levels. The `max_cycles`\n",
    "    parameter controls the maximum number of mode oscillations in any given time scale \n",
    "    that qualify as \"slow\". The `do_svht` parameter indicates whether or not to perform\n",
    "    optimal singular value hard thresholding.\n",
    "\n",
    "    More info here: https://humaticlabs.com/blog/mrdmd-python/\n",
    "    \"\"\"\n",
    "\n",
    "    # 4 times nyquist limit to capture cycles\n",
    "    nyq = 8 * max_cycles\n",
    "\n",
    "    # time bin size\n",
    "    bin_size = D.shape[1]\n",
    "    if bin_size < nyq:\n",
    "        return []\n",
    "\n",
    "    # extract subsamples \n",
    "    step = floor(bin_size / nyq) # max step size to capture cycles\n",
    "    _D = D[:,::step]\n",
    "    X = _D[:,:-1]\n",
    "    Y = _D[:,1:]\n",
    "\n",
    "    # determine rank-reduction\n",
    "    if do_svht:\n",
    "        _sv = svdvals(_D)\n",
    "        tau = svht(_D, sv=_sv)\n",
    "        r = sum(_sv > tau)\n",
    "    else:\n",
    "        r = min(X.shape)\n",
    "\n",
    "    # compute dmd\n",
    "    mu,Phi = dmd(X, Y, r)\n",
    "\n",
    "    # frequency cutoff (oscillations per timestep)\n",
    "    rho = max_cycles / bin_size\n",
    "\n",
    "    # consolidate slow eigenvalues (as boolean mask)\n",
    "    slow = (np.abs(np.log(mu) / (2 * pi * step))) <= rho\n",
    "    n = sum(slow) # number of slow modes\n",
    "\n",
    "    # extract slow modes (perhaps empty)\n",
    "    mu = mu[slow]\n",
    "    Phi = Phi[:,slow]\n",
    "\n",
    "    if n > 0:\n",
    "\n",
    "        # vars for the objective function for D (before subsampling)\n",
    "        Vand = np.vander(power(mu, 1/step), bin_size, True)\n",
    "        P = multiply(dot(Phi.conj().T, Phi), np.conj(dot(Vand, Vand.conj().T)))\n",
    "        q = np.conj(diag(dot(dot(Vand, D.conj().T), Phi)))\n",
    "\n",
    "        # find optimal b solution\n",
    "        b_opt = solve(P, q).squeeze()\n",
    "\n",
    "        # time evolution\n",
    "        Psi = (Vand.T * b_opt).T\n",
    "\n",
    "    else:\n",
    "\n",
    "        # zero time evolution\n",
    "        b_opt = np.array([], dtype='complex')\n",
    "        Psi = np.zeros([0, bin_size], dtype='complex')\n",
    "\n",
    "    # dmd reconstruction\n",
    "    D_dmd = dot(Phi, Psi)   \n",
    "\n",
    "    # remove influence of slow modes\n",
    "    D = D - D_dmd\n",
    "\n",
    "    # record keeping\n",
    "    node = type('Node', (object,), {})()\n",
    "    node.level = level            # level of recursion\n",
    "    node.bin_num = bin_num        # time bin number\n",
    "    node.bin_size = bin_size      # time bin size\n",
    "    node.start = offset           # starting index\n",
    "    node.stop = offset + bin_size # stopping index\n",
    "    node.step = step              # step size\n",
    "    node.rho = rho                # frequency cutoff\n",
    "    node.r = r                    # rank-reduction\n",
    "    node.n = n                    # number of extracted modes\n",
    "    node.mu = mu                  # extracted eigenvalues\n",
    "    node.Phi = Phi                # extracted DMD modes\n",
    "    node.Psi = Psi                # extracted time evolution\n",
    "    node.b_opt = b_opt            # extracted optimal b vector\n",
    "    nodes = [node]\n",
    "\n",
    "    # split data into two and do recursion\n",
    "    if level < max_levels:\n",
    "        split = ceil(bin_size / 2) # where to split\n",
    "        nodes += mrdmd(\n",
    "            D[:,:split],\n",
    "            level=level+1,\n",
    "            bin_num=2*bin_num,\n",
    "            offset=offset,\n",
    "            max_levels=max_levels,\n",
    "            max_cycles=max_cycles,\n",
    "            do_svht=do_svht\n",
    "            )\n",
    "        nodes += mrdmd(\n",
    "            D[:,split:],\n",
    "            level=level+1,\n",
    "            bin_num=2*bin_num+1,\n",
    "            offset=offset+split,\n",
    "            max_levels=max_levels,\n",
    "            max_cycles=max_cycles,\n",
    "            do_svht=do_svht\n",
    "            )\n",
    "\n",
    "    return nodes\n",
    "\n",
    "def stitch(nodes, level):\n",
    "    \n",
    "    # get length of time dimension\n",
    "    start = min([nd.start for nd in nodes])\n",
    "    stop = max([nd.stop for nd in nodes])\n",
    "    t = stop - start\n",
    "\n",
    "    # extract relevant nodes\n",
    "    nodes = [n for n in nodes if n.level == level]\n",
    "    nodes = sorted(nodes, key=lambda n: n.bin_num)\n",
    "    \n",
    "    # stack DMD modes\n",
    "    Phi = np.hstack([n.Phi for n in nodes])\n",
    "    \n",
    "    # allocate zero matrix for time evolution\n",
    "    nmodes = sum([n.n for n in nodes])\n",
    "    Psi = np.zeros([nmodes, t], dtype='complex')\n",
    "    \n",
    "    # copy over time evolution for each time bin\n",
    "    i = 0\n",
    "    for n in nodes:\n",
    "        _nmodes = n.Psi.shape[0]\n",
    "        Psi[i:i+_nmodes,n.start:n.stop] = n.Psi\n",
    "        i += _nmodes\n",
    "    \n",
    "    return Phi,Psi\n",
    "\n",
    "def mr_recon(D):\n",
    "    nodes = mrdmd(D)\n",
    "    \n",
    "    Phi0,Psi0 = stitch(nodes, 0)\n",
    "    Phi1,Psi1 = stitch(nodes, 1)\n",
    "    Phi2,Psi2 = stitch(nodes, 2)\n",
    "    \n",
    "    levels = sorted({nd.level for nd in nodes})\n",
    "    D_hat_full = sum(stitch(nodes, l)[0] @ stitch(nodes, l)[1] for l in levels)\n",
    "    \n",
    "    D_iter = None\n",
    "    for l in levels:\n",
    "        fig, axes = plt.subplots(1,2, figsize=(15,5))\n",
    "        ax = axes[1]\n",
    "        _d = stitch(nodes, l)[0] @ stitch(nodes, l)[1]\n",
    "        sns.heatmap(_d.real, cbar=False, square=True, ax=ax)\n",
    "        ax.set_axis_off()\n",
    "        \n",
    "        if D_iter is None:\n",
    "            D_iter = _d.real\n",
    "        else:\n",
    "            D_iter = D_iter + _d.real\n",
    "            \n",
    "        ax = axes[0]\n",
    "        sns.heatmap(D_iter, cbar=False, square=True, ax=ax)\n",
    "        ax.set_axis_off()\n",
    "        plt.show()\n",
    "        \n",
    "    return nodes\n",
    "\n",
    "def plot_eigs(nodes, levels, combined=False):\n",
    "    p = np.linspace(0, 2*np.pi, 100)\n",
    "    \n",
    "    if combined:\n",
    "        # all on one plot\n",
    "        fix,ax = plt.subplots(1,1)\n",
    "        ax.plot(np.cos(p), np.sin(p), c=\"k\")\n",
    "        \n",
    "        for l in levels:\n",
    "            ns = [n for n in nodes if n.level == l]\n",
    "            eigs = []\n",
    "            for n in ns:\n",
    "                eigs.extend(n.mu)\n",
    "            eigs = np.array(eigs)\n",
    "            ax.scatter(eigs.real, eigs.imag, alpha=0.25, label=l)\n",
    "        \n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_title('wrt unit circle')\n",
    "        ax.legend()\n",
    "        ax.set_xlim(left = 0)\n",
    "        \n",
    "        ax.set_xlabel('Re'); ax.set_ylabel('Im')\n",
    "    else:\n",
    "        fix,axes = plt.subplots(1,len(levels), sharey=True)\n",
    "        # plot unit circle\n",
    "        for idx,l in enumerate(levels):\n",
    "            ax = axes[idx]\n",
    "            ax.plot(np.cos(p), np.sin(p), c=\"k\")\n",
    "            \n",
    "            ns = [n for n in nodes if n.level == l]\n",
    "            eigs = []\n",
    "            for n in ns:\n",
    "                eigs.extend(n.mu)\n",
    "            eigs = np.array(eigs)\n",
    "            ax.scatter(eigs.real, eigs.imag, alpha=.5, c='red', label=l)\n",
    "        \n",
    "            ax.set_aspect(\"equal\")\n",
    "            ax.set_xlim(left = 0, right=1.2)\n",
    "            ax.set_title(f'level {l}')\n",
    "            ax.set_axis_off()\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../datasets/NNN/'\n",
    "dat = pd.read_pickle(os.path.join(DATA_DIR, ('face_roi_data.pkl')))\n",
    "print(f'Unique face ROIs: {list(dat['roi'].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = 'MF1_8_F' # Unknown_19_F\n",
    "PVAL = 0.05\n",
    "\n",
    "# load in per-image psth\n",
    "sig = dat[dat['p_value'] < PVAL]\n",
    "df = sig[sig['roi'] == ROI]\n",
    "X = np.stack(df['img_psth'].to_numpy())\n",
    "print(f'Loaded unit-level data for each image. Shape:', X.shape, '---> (units, time points, images)')\n",
    "\n",
    "# center the data per unit and per image\n",
    "X_centered = X - X.mean(axis=1, keepdims=True)\n",
    "print('Centered shape:', X_centered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sets = {\n",
    "    \"all_faces\":  np.arange(1000, 1024),\n",
    "    \"all_bodies\": np.concatenate([\n",
    "        np.arange(1025, 1031),\n",
    "        np.arange(1042, 1048),\n",
    "        np.arange(1049, 1061)\n",
    "    ]),\n",
    "    \"all_objects\": np.concatenate([\n",
    "        np.arange(1024,1025),\n",
    "        np.arange(1031, 1042),\n",
    "        np.arange(1048,1049),\n",
    "        np.arange(1061, 1072)\n",
    "    ])\n",
    "}\n",
    "\n",
    "for k,v in img_sets.items():\n",
    "    print('\\n\\n\\n\\n====================================================================================')\n",
    "    print(f'================================== {k} ============================================ ')\n",
    "    print('====================================================================================')\n",
    "    \n",
    "    X_cat = X_centered[:, :, v]\n",
    "    X_cat = np.mean(X_cat, axis=2)\n",
    "\n",
    "    fig,axes = plt.subplots(1,2, figsize=(15,5))\n",
    "    ax = axes[0]\n",
    "    sns.heatmap(X_cat, cbar=False, square=True, ax=ax)\n",
    "    ax.set_title(f'Unit responses for {k}')\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    ax = axes[1]\n",
    "    sns.lineplot(X_cat.T)\n",
    "    ax.get_legend().remove()\n",
    "    plt.show()\n",
    "\n",
    "    # nodes = mr_recon(X_cat)\n",
    "    nodes = mrdmd(X_cat)\n",
    "    levels = sorted({nd.level for nd in nodes})\n",
    "    plot_eigs(nodes, levels)\n",
    "\n",
    "    E_levels = []\n",
    "    for level in levels:\n",
    "        Phi_l, Psi_l = stitch(nodes, level)\n",
    "        E_levels.append(np.linalg.norm(Phi_l @ Psi_l, 'fro')**2)\n",
    "    E_levels = np.array(E_levels)\n",
    "    E_levels /= E_levels.sum()  # fraction of total energy\n",
    "    \n",
    "    sns.barplot(E_levels)\n",
    "    plt.show()\n",
    "    \n",
    "    levels = sorted({nd.level for nd in nodes})\n",
    "    E, bands = [], []\n",
    "    f_max = 0\n",
    "    for l in levels:\n",
    "        Phi, Psi = stitch(nodes, l)\n",
    "        E.append(np.linalg.norm(Phi @ Psi, 'fro')**2)\n",
    "        # approximate band (0 .. f_max for that level)\n",
    "        bin_len = max(nd.bin_size for nd in nodes if nd.level == l)\n",
    "        rho = np.mean([nd.rho for nd in nodes if nd.level == l])\n",
    "        dt = 1\n",
    "        f_min = f_max\n",
    "        f_max = rho / dt * 1000  # since nd.rho = max_cycles / bin_size\n",
    "        bands.append((f_min, f_max))\n",
    "    E = np.array(E) / np.sum(E)\n",
    "    \n",
    "    for l,(lo,hi),e in zip(levels,bands,E):\n",
    "        print(f\"level {l}  energy={e:.2f}  band≈[{lo:.3f}, {hi:.3f}] MHz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMAL DMD on category level dynamics\n",
    "Xi_ = X_cat[:, :-1]\n",
    "Yi_ = X_cat[:,  1:]\n",
    "print('Xt and Yt shape:', Xi_.shape, Yi_.shape)\n",
    "\n",
    "# determine rank-reduction\n",
    "sv = svdvals(Xi_)\n",
    "tau = svht(Xi_, sv=sv)\n",
    "r = sum(sv > tau)\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "sns.scatterplot(x=range(len(sv)), y=sv, ax=ax)\n",
    "ax.axhline(tau, color='red', linestyle='dashed', linewidth=0.75)\n",
    "ax.set_title(f'Optimal rank for rank reduction: r={r}')\n",
    "plt.show()\n",
    "\n",
    "t = np.arange(Xi_.shape[1])\n",
    "\n",
    "# do dmd\n",
    "mu,Phi = dmd(Xi_, Yi_, r)\n",
    "\n",
    "# compute time evolution\n",
    "b = dot(pinv(Phi), Xi_[:,0])\n",
    "Vand = np.vander(mu, len(t), True)\n",
    "Psi = (Vand.T * b).T\n",
    "\n",
    "\n",
    "# 1) initial amplitudes (b): solve Phi @ b ≈ X[:,0]\n",
    "b, *_ = np.linalg.lstsq(Phi, Xi_[:, 0], rcond=None)  # (r,)\n",
    "\n",
    "# 2) time dynamics (Psi): Psi[k,t] = b[k] * mu[k]**t\n",
    "Psi = (b[:, None]) * np.power(mu[:, None], t[None, :])  # shape (r, Trec)\n",
    "\n",
    "# 3) reconstruction\n",
    "Xhat = Phi @ Psi\n",
    "\n",
    "Xhat = Xhat.real\n",
    "\n",
    "fig,axes = plt.subplots(2,1, figsize=(12,10))\n",
    "ax = axes[0]\n",
    "sns.heatmap(Xi_[:, :450], label=\"data\", cbar=False, square=True, ax=ax)\n",
    "ax.set_axis_off()\n",
    "ax.set_title('Original')\n",
    "\n",
    "ax = axes[1]\n",
    "sns.heatmap(Xhat[:, :450], label=\"DMD recon\", cbar=False, square=True, ax=ax)\n",
    "ax.set_axis_off()\n",
    "ax.set_title('Reconstructed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = X_cat\n",
    "print(D.shape)\n",
    "nodes = mrdmd(D)\n",
    "\n",
    "Phi0,Psi0 = stitch(nodes, 0)\n",
    "Phi1,Psi1 = stitch(nodes, 1)\n",
    "Phi2,Psi2 = stitch(nodes, 2)\n",
    "\n",
    "levels = sorted({nd.level for nd in nodes})\n",
    "D_hat_full = sum(stitch(nodes, l)[0] @ stitch(nodes, l)[1] for l in levels)\n",
    "\n",
    "D_iter = None\n",
    "for l in levels:\n",
    "    fig, axes = plt.subplots(1,2, figsize=(15,5))\n",
    "    ax = axes[1]\n",
    "    _d = stitch(nodes, l)[0] @ stitch(nodes, l)[1]\n",
    "    sns.heatmap(_d.real, cbar=False, square=True, ax=ax)\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    if D_iter is None:\n",
    "        D_iter = _d.real\n",
    "    else:\n",
    "        D_iter = D_iter + _d.real\n",
    "        \n",
    "    ax = axes[0]\n",
    "    sns.heatmap(D_iter, cbar=False, square=True, ax=ax)\n",
    "    ax.set_axis_off()\n",
    "    plt.show()\n",
    "\n",
    "i = 50\n",
    "plt.plot(D[i], label='data')\n",
    "plt.plot(D_hat_full[i].real, '--', label='MRDMD recon')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix,axes = plt.subplots(1,len(levels), sharey=True)\n",
    "\n",
    "# plot unit circle\n",
    "p = np.linspace(0, 2*np.pi, 100)\n",
    "\n",
    "for idx,l in enumerate(levels):\n",
    "    ax = axes[idx]\n",
    "    ax.plot(np.cos(p), np.sin(p), c=\"k\")\n",
    "    \n",
    "    ns = [n for n in nodes if n.level == l]\n",
    "    eigs = []\n",
    "    for n in ns:\n",
    "        eigs.extend(n.mu)\n",
    "    eigs = np.array(eigs)\n",
    "    ax.scatter(eigs.real, eigs.imag, alpha=.5, c='red', label=l)\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlim(left = 0, right=1.2)\n",
    "    ax.set_title(f'level {l}')\n",
    "    ax.set_axis_off()\n",
    "\n",
    "# all on one plot\n",
    "fix,ax = plt.subplots(1,1)\n",
    "\n",
    "# plot unit circle\n",
    "ax.plot(np.cos(p), np.sin(p), c=\"k\")\n",
    "\n",
    "for l in levels:\n",
    "    ns = [n for n in nodes if n.level == l]\n",
    "    eigs = []\n",
    "    for n in ns:\n",
    "        eigs.extend(n.mu)\n",
    "    eigs = np.array(eigs)\n",
    "    ax.scatter(eigs.real, eigs.imag, alpha=0.25, label=l)\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title('wrt unit circle')\n",
    "ax.legend()\n",
    "ax.set_xlim(left = 0)\n",
    "\n",
    "ax.set_xlabel('Re'); ax.set_ylabel('Im')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_levels = []\n",
    "for level in levels:\n",
    "    Phi_l, Psi_l = stitch(nodes, level)\n",
    "    E_levels.append(np.linalg.norm(Phi_l @ Psi_l, 'fro')**2)\n",
    "E_levels = np.array(E_levels)\n",
    "E_levels /= E_levels.sum()  # fraction of total energy\n",
    "\n",
    "sns.barplot(E_levels)\n",
    "\n",
    "levels = sorted({nd.level for nd in nodes})\n",
    "E, bands = [], []\n",
    "f_max = 0\n",
    "for l in levels:\n",
    "    Phi, Psi = stitch(nodes, l)\n",
    "    E.append(np.linalg.norm(Phi @ Psi, 'fro')**2)\n",
    "    # approximate band (0 .. f_max for that level)\n",
    "    bin_len = max(nd.bin_size for nd in nodes if nd.level == l)\n",
    "    rho = np.mean([nd.rho for nd in nodes if nd.level == l])\n",
    "    dt = 1\n",
    "    f_min = f_max\n",
    "    f_max = rho / dt * 1000  # since nd.rho = max_cycles / bin_size\n",
    "    bands.append((f_min, f_max))\n",
    "E = np.array(E) / np.sum(E)\n",
    "\n",
    "for l,(lo,hi),e in zip(levels,bands,E):\n",
    "    print(f\"level {l}  energy={e:.2f}  band≈[{lo:.3f}, {hi:.3f}] MHz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_energy(nodes):\n",
    "    levs = sorted({n.level for n in nodes})\n",
    "    E = []\n",
    "    for ℓ in levs:\n",
    "        Phi, Psi = stitch(nodes, ℓ)\n",
    "        E.append(np.linalg.norm(Phi @ Psi, 'fro')**2)\n",
    "    E = np.array(E); return E / E.sum()\n",
    "\n",
    "category_E = {}\n",
    "Edf = pd.DataFrame(columns=['level', 'energy', 'category'])\n",
    "for k, v in img_sets.items():\n",
    "    # energy matrix: images × levels\n",
    "    E_cat = np.vstack([\n",
    "        level_energy(mrdmd(X_centered[:, :, i], max_levels=5))\n",
    "        for i in v\n",
    "    ])\n",
    "    category_E[k] = E_cat\n",
    "\n",
    "    # store all values, one row per image × level\n",
    "    for img_idx in range(E_cat.shape[0]):\n",
    "        for level_idx in range(E_cat.shape[1]):\n",
    "            Edf.loc[len(Edf)] = {\n",
    "                'level': level_idx,\n",
    "                'energy': E_cat[img_idx, level_idx],\n",
    "                'category': k.split('_')[-1]\n",
    "            }\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "sns.barplot(data=Edf, x='level', y='energy', hue='category', estimator = 'median', errorbar='se', ax=ax)\n",
    "ax.set_title('Per-level Energy')\n",
    "sns.despine(fig=fig, trim=True, offset=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = img_sets['all_faces']\n",
    "\n",
    "X_cat = np.concatenate([X_centered[:, :, i] for i in v], axis=1)  # (units, time*images)\n",
    "nodes = mrdmd(X_cat, max_levels=5)\n",
    "\n",
    "theta = np.linspace(0, 2*np.pi, 400)\n",
    "plt.plot(np.cos(theta), np.sin(theta), 'k--')\n",
    "\n",
    "# for name, nodes in cat_nodes.items():\n",
    "mu = np.concatenate([n.mu for n in nodes])\n",
    "plt.scatter(mu.real, mu.imag, label='face', alpha=0.7)\n",
    "\n",
    "plt.gca().set_aspect('equal'); plt.legend()\n",
    "plt.xlabel('Re(λ)'); plt.ylabel('Im(λ)')\n",
    "plt.title('Category-level DMD spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_cat: (units, T_cat) = time-concat of the 24 images in a category\n",
    "# cuts: list of (start, stop) indices delimiting each image within D_cat\n",
    "v = img_sets['all_faces']\n",
    "D_cat = np.concatenate([X_centered[:, :, i] for i in v], axis=1)  # (units, time*images)\n",
    "T = 450\n",
    "cuts = [(T*t, (1+t)*T) for t in range(24)]\n",
    "\n",
    "def mr_recon(D, max_levels=5):\n",
    "    nodes = mrdmd(D, max_levels=max_levels)\n",
    "    levels = sorted({nd.level for nd in nodes})\n",
    "    Dhat = sum((lambda p: p[0] @ p[1])(stitch(nodes, l)) for l in levels)\n",
    "    return Dhat.real, nodes\n",
    "\n",
    "# 1) category-shared fit and recon\n",
    "Dhat_cat, nodes_cat = mr_recon(D_cat, max_levels = 24*5)\n",
    "\n",
    "# 2) per-image fits and recons\n",
    "errs_cat, errs_indiv = [], []\n",
    "for (a,b) in cuts:\n",
    "    Xi = D_cat[:, a:b]\n",
    "    # per-image recon\n",
    "    Xhat_indiv, _ = mr_recon(Xi)\n",
    "\n",
    "    # slice the category recon to the same interval\n",
    "    Xhat_cat = Dhat_cat[:, a:b]\n",
    "\n",
    "    fig,axes = plt.subplots(1,2)\n",
    "    ax = axes[0]\n",
    "    sns.heatmap(Xhat_indiv, cbar=False, ax=ax)\n",
    "    ax.set_axis_off()\n",
    "    ax = axes[1]\n",
    "    sns.heatmap(Xhat_cat, cbar=False, ax=ax)\n",
    "    ax.set_axis_off()\n",
    "    plt.show()\n",
    "    \n",
    "    # normalized Frobenius errors\n",
    "    denom = np.linalg.norm(Xi)\n",
    "    errs_indiv.append(np.linalg.norm(Xi - Xhat_indiv)/denom)\n",
    "    errs_cat.append(  np.linalg.norm(Xi - Xhat_cat)/denom)\n",
    "\n",
    "# paired comparison (per image)\n",
    "errs_indiv = np.array(errs_indiv)\n",
    "errs_cat   = np.array(errs_cat)\n",
    "gap = errs_cat - errs_indiv  # >0 means category model worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "p = np.linspace(0, 2*np.pi, 100)\n",
    "ax.plot(np.cos(p), np.sin(p), c=\"k\")\n",
    "\n",
    "levels = sorted({nd.level for nd in nodes_cat})\n",
    "for l in levels:\n",
    "    ns = [n for n in nodes_cat if n.level == l]\n",
    "    eigs = []\n",
    "    for n in ns:\n",
    "        eigs.extend(n.mu)\n",
    "    eigs = np.array(eigs)\n",
    "    ax.scatter(eigs.real, eigs.imag, alpha=0.25, label=l)\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title('wrt unit circle')\n",
    "ax.legend()\n",
    "# ax.set_xlim(left = 0)\n",
    "\n",
    "ax.set_xlabel('Re'); ax.set_ylabel('Im')\n",
    "\n",
    "fix,axes = plt.subplots(1,len(levels), figsize=(len(levels),len(levels)//2), sharey=True)\n",
    "# plot unit circle\n",
    "p = np.linspace(0, 2*np.pi, 100)\n",
    "\n",
    "for idx,l in enumerate(levels):\n",
    "    ax = axes[idx]\n",
    "    ax.plot(np.cos(p), np.sin(p), c=\"k\")\n",
    "    \n",
    "    ns = [n for n in nodes_cat if n.level == l]\n",
    "    eigs = []\n",
    "    for n in ns:\n",
    "        eigs.extend(n.mu)\n",
    "    eigs = np.array(eigs)\n",
    "    ax.scatter(eigs.real, eigs.imag, alpha=.25, c='red', label=l)\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlim(left = 0, right=1.2)\n",
    "    ax.set_title(f'{l}')\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = sorted({nd.level for nd in nodes_cat})\n",
    "out = []\n",
    "for l in levels:\n",
    "    bin_sizes = [nd.bin_size for nd in nodes_cat if nd.level==l]\n",
    "    # they’re equal within level if you split evenly:\n",
    "    B = max(bin_sizes)\n",
    "    fmax = (nodes_cat[0].rho * B) / (nodes_cat[0].step * nodes_cat[0].bin_size)  # or simply max_cycles/(B*dt)\n",
    "    # use the definition you used for rho; simplest:\n",
    "    # fmax = max_cycles / (B * dt)\n",
    "    out.append((l, B, B*dt, fmax))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(dynamics)",
   "language": "python",
   "name": "dynamics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
