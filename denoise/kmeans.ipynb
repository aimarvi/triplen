{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from gsn.perform_gsn import perform_gsn\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d, uniform_filter1d\n",
    "\n",
    "# raw: (units, time, images, trials)\n",
    "def psth_gaussian(raw, sigma=3):\n",
    "    # smooth along the time axis\n",
    "    psth = gaussian_filter1d(raw, sigma=sigma, axis=1)\n",
    "    return psth\n",
    "\n",
    "def psth_window(raw, window_ms=50):\n",
    "    # raw: (units, time, images, trials)\n",
    "    # convert NaN to 0 so windowing behaves properly\n",
    "    X = np.nan_to_num(raw, nan=0.0)\n",
    "    # sliding window average over time axis\n",
    "    psth = uniform_filter1d(X, size=window_ms, axis=1, mode='constant')\n",
    "    return psth\n",
    "\n",
    "def summary(x):\n",
    "    print(f'''Summary statistics {x.shape}:\n",
    "    \\tMedian: {np.nanmedian(x)}\n",
    "    \\tMean: {np.nanmean(x)}\n",
    "    \\tMinimum: {np.nanmin(x)}\n",
    "    \\tMaximum:{np.nanmax(x)}\\n''')\n",
    "\n",
    "def segregate(df, method='truncate'):\n",
    "    roi_arrays = {}\n",
    "    for roi, df_roi in df.groupby('roi'):\n",
    "        arrays = df_roi['raster'].to_list()\n",
    "        if method == 'truncate':\n",
    "            # count valid trials per unit\n",
    "            valid_counts = []\n",
    "            valid_masks  = []\n",
    "\n",
    "            # minimum trials with no NaNs\n",
    "            for a in arrays:\n",
    "                vm = ~np.isnan(a).any(axis=(0,1))\n",
    "                valid_masks.append(vm)\n",
    "                valid_counts.append(vm.sum())\n",
    "            min_T = min(valid_counts)\n",
    "        \n",
    "            total = []\n",
    "            for a, vm in zip(arrays, valid_masks):\n",
    "                idx = np.where(vm)[0][:min_T]   # first min_T valid trials\n",
    "                total.append(a[:, :, idx])\n",
    "        elif method == 'pad':\n",
    "            # find max number of trials *within this ROI*\n",
    "            max_T = max(a.shape[2] for a in arrays)\n",
    "            total = []\n",
    "            for a in arrays:\n",
    "                T = a.shape[2]\n",
    "                if T < max_T:\n",
    "                    pad_width = ((0, 0), (0, 0), (0, max_T - T))\n",
    "                    a = np.pad(a, pad_width, constant_values=np.nan)\n",
    "                total.append(a)\n",
    "\n",
    "        x_roi = np.array(total)   # (units, 450, 1072, min_T)\n",
    "        roi_arrays[roi] = x_roi\n",
    "        print(roi, x_roi.shape)\n",
    "\n",
    "    return roi_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ras_df = pd.read_pickle('../../datasets/NNN/raw_raster_data_batch000.pkl')\n",
    "print(f'Succesfully loaded data for {len(ras_df)} units.')\n",
    "\n",
    "roi_arrays = segregate(ras_df, method='truncate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CLUSTER UNITS USING K-MEANS\n",
    "ROI = 'Unknown_19_F'\n",
    "x = roi_arrays[ROI] # shape: (608, 450, 1072, reps)\n",
    "unit_tc = np.nanmean(x, axis=(2, 3))\n",
    "\n",
    "k = 3  # number of clusters you want\n",
    "kmeans = KMeans(n_clusters=k, random_state=0, n_init='auto')\n",
    "labels = kmeans.fit_predict(unit_tc)\n",
    "\n",
    "cluster_data = {}  # cluster_id -> (n_units_in_cluster, 450, 1072, 7)\n",
    "for c in range(k):\n",
    "    idx = np.where(labels == c)[0]\n",
    "    cluster_data[c] = x[idx]   # keeps full (time, images, trials) for those units\n",
    "    print(f\"Cluster {c}: {cluster_data[c].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VISUALIZE CLUSTER TIME COURSES\n",
    "\n",
    "# first for a single unit\n",
    "uidx = 8\n",
    "img_avg = np.mean(cluster_data[2], axis=2)\n",
    "\n",
    "unit_tc = img_avg[uidx]                      # (time, trials)\n",
    "unit_tc = unit_tc / np.max(unit_tc, axis=0, keepdims=True)\n",
    "# now each column (trial) peaks at 1\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "for trial in range(unit_tc.shape[-1]):\n",
    "    trial_tc = unit_tc[:, trial]\n",
    "    sns.lineplot(trial_tc, label=trial, alpha=0.5, ax=ax)\n",
    "ax.legend()\n",
    "ax.set_title('Single unit data across 5 trials')\n",
    "plt.show()\n",
    "\n",
    "# now for the entire cluster\n",
    "trial_avg = np.mean(img_avg, axis=2)                     # (units, time)\n",
    "unit_norm = trial_avg / np.max(trial_avg, axis=1, keepdims=True)\n",
    "# axis=1 so each unitâ€™s own max over time is 1\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "for unit in unit_norm[:50]:\n",
    "    sns.lineplot(unit, alpha=0.5, label = unit, ax=ax)\n",
    "ax.legend().remove()\n",
    "ax.set_title('Each line is a unit, averaged across 5 trials')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(dynamics)",
   "language": "python",
   "name": "dynamics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
